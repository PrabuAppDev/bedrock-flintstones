{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd771a29-f732-4513-8566-7bbfe6ccca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Fetch inference profile ARN from environment variables\n",
    "bedrock_inference_profile_arn = os.getenv(\"BEDROCK_INFERENCE_PROFILE_ARN\")\n",
    "\n",
    "# Initialize the Bedrock Runtime client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    region_name=os.getenv(\"AWS_REGION\")\n",
    ")\n",
    "\n",
    "def invoke_bedrock_model(profile_arn, payload):\n",
    "    \"\"\"\n",
    "    Invoke a Bedrock model using the inference profile ARN.\n",
    "\n",
    "    Args:\n",
    "        profile_arn (str): ARN of the Bedrock inference profile.\n",
    "        payload (dict): Input payload for the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Response from the Bedrock model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Invoking Bedrock model\")\n",
    "        \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=profile_arn,\n",
    "            body=json.dumps(payload),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        # Parse and return the response\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        return response_body\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error invoking model with ARN {profile_arn}: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Payload for the smart home agent's winter preparation task\n",
    "smart_home_payload = {\n",
    "    \"prompt\": \"\"\"Prepare the house for winter by optimizing thermostat, plumbing, lighting, garage, and garden. \n",
    "Ensure pipes won't freeze and all systems are secure.\"\"\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "# Call the Bedrock model\n",
    "try:\n",
    "    smart_home_response = invoke_bedrock_model(bedrock_inference_profile_arn, smart_home_payload)\n",
    "    \n",
    "    # Print the raw response\n",
    "    print(\"Smart Home Agent Response:\")\n",
    "    print(json.dumps(smart_home_response, indent=2))\n",
    "\n",
    "    # Extract and print generated instructions\n",
    "    generated_text = smart_home_response.get(\"generation\", \"No generation found\")\n",
    "    print(\"\\nGenerated Instructions:\\n\", generated_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a564499-acf4-43fb-96f0-8c57794a2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Initialize Logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Fetch environment variables\n",
    "agent_id = os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ID\")\n",
    "alias_id = os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ALIAS_ID\")\n",
    "region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "# Validate environment variables\n",
    "if not agent_id:\n",
    "    raise ValueError(\"Environment variable AWS_BEDROCK_SMART_HOME_AGENT_ID must be set.\")\n",
    "if not alias_id:\n",
    "    raise ValueError(\"Environment variable AWS_BEDROCK_SMART_HOME_AGENT_ALIAS_ID must be set.\")\n",
    "if not region:\n",
    "    raise ValueError(\"Environment variable AWS_REGION must be set.\")\n",
    "\n",
    "# Initialize Bedrock Agent Runtime Client\n",
    "bedrock_agent_runtime_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_ncame=region\n",
    ")\n",
    "\n",
    "# Log setup details (avoid logging sensitive data like credentials)\n",
    "logger.info(\"Initialized Bedrock Agent Runtime Client with environment configurations successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9f743-89e3-4779-b052-bf7837f583a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the payload for the Bedrock inference model\n",
    "smart_home_payload = {\n",
    "    \"prompt\": \"\"\"\n",
    "    You are an AI assistant for smart home automation. \n",
    "    Help the user prepare their house for winter by providing specific, actionable instructions to optimize:\n",
    "    1. Thermostat (to prevent pipes from freezing)\n",
    "    2. Lighting\n",
    "\n",
    "    Provide these instructions in a simple, step-by-step format.\n",
    "    \"\"\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "# Call the Bedrock inference model\n",
    "try:\n",
    "    # Ensure the inference profile ARN is set\n",
    "    if not bedrock_inference_profile_arn:\n",
    "        raise ValueError(\"Environment variable BEDROCK_INFERENCE_PROFILE_ARN must be set.\")\n",
    "\n",
    "    smart_home_response = invoke_bedrock_model(bedrock_inference_profile_arn, smart_home_payload)\n",
    "\n",
    "    # Print the raw response\n",
    "    print(\"Smart Home AI Assistant Response:\")\n",
    "    print(json.dumps(smart_home_response, indent=2))\n",
    "\n",
    "    # Extract and display the generated instructions\n",
    "    generated_text = smart_home_response.get(\"generation\", \"No generation found\")\n",
    "    print(\"\\nGenerated Instructions:\\n\", generated_text)\n",
    "\n",
    "    # Optionally, invoke the action groups if needed\n",
    "    if \"thermostat\" in generated_text.lower():\n",
    "        print(\"\\nPreparing to adjust the thermostat as per instructions...\")\n",
    "        # Placeholder for invoking thermostat-specific actions\n",
    "        # Invoke actions through Bedrock Agent Runtime or specific APIs\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during winter preparation task: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3fa54-ed29-4f50-9ac7-d87c8d06a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse AI instructions and interact with the Bedrock agent runtime\n",
    "try:\n",
    "    # Extract actionable instructions from the AI response\n",
    "    ai_instructions = smart_home_response.get(\"generation\", \"\")\n",
    "    print(\"Generated AI Instructions:\\n\", ai_instructions)\n",
    "\n",
    "    # Simulate parsing instructions (e.g., thermostat-related actions)\n",
    "    if \"thermostat\" in ai_instructions.lower():\n",
    "        # Define session ID for Bedrock Agent\n",
    "        import uuid\n",
    "        session_id = str(uuid.uuid4())\n",
    "\n",
    "        # Create a thermostat-specific action\n",
    "        action_payload = {\n",
    "            \"actionGroup\": \"action_group_thermostat\",\n",
    "            \"function\": \"set_temperature\",\n",
    "            \"parameters\": {\n",
    "                \"temperature\": 68,  # Example: Set thermostat to 68Â°F\n",
    "                \"mode\": \"consistent\"  # Example mode for consistency\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Invoke Bedrock Agent Runtime\n",
    "        agent_response = bedrock_agent_runtime_client.invoke_agent(\n",
    "            agentId=os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ID\"),\n",
    "            agentAliasId=os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ALIAS_ID\"),\n",
    "            sessionId=session_id,\n",
    "            inputText=f\"Adjust thermostat as per the instructions: {action_payload}\",\n",
    "        )\n",
    "\n",
    "        # Print agent response\n",
    "        print(\"\\nAgent Response for Thermostat Action:\")\n",
    "        # print(agent_response) #uncomment for debugging and has sensitive data such as session ID\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing and invoking agent actions: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715acc6-8b1c-4a9a-a4e7-c8573ad91cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Bedrock Agent Client\n",
    "region = os.getenv(\"AWS_REGION\")\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent\", region_name=region)\n",
    "\n",
    "def list_agents():\n",
    "    \"\"\"\n",
    "    List all agents in the Bedrock service.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Listing all Bedrock agents...\")\n",
    "        response = bedrock_agent_client.list_agents()\n",
    "\n",
    "        # Process the response\n",
    "        agents = response.get(\"agents\", [])\n",
    "        if agents:\n",
    "            logger.info(f\"Found {len(agents)} agents:\")\n",
    "            for agent in agents:\n",
    "                print(json.dumps(agent, indent=2))\n",
    "        else:\n",
    "            logger.info(\"No agents found.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing agents: {e}\")\n",
    "\n",
    "# Call the function\n",
    "list_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4142180-21e3-4d1a-9afa-fd0280f3bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "boto3.set_stream_logger('', logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Environment Variables\n",
    "agent_id = os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ID\")\n",
    "alias_id = os.getenv(\"AWS_BEDROCK_SMART_HOME_AGENT_ALIAS_ID\")\n",
    "region = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "# Initialize Bedrock Agent Runtime Client\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "def invoke_agent_with_roc(prompt_text, session_id=None):\n",
    "    \"\"\"\n",
    "    Invokes the Bedrock Agent with a prompt and handles Return of Control events.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send request to the agent\n",
    "        logger.info(f\"Invoking agent with prompt: {prompt_text}\")\n",
    "        response = bedrock_agent_runtime.invoke_agent(\n",
    "            agentId=agent_id,\n",
    "            agentAliasId=alias_id,\n",
    "            sessionId=session_id or \"roc-session\",\n",
    "            inputText=prompt_text,\n",
    "            enableTrace=True\n",
    "        )\n",
    "\n",
    "        # Extract event stream\n",
    "        event_stream = response.get(\"completion\", [])\n",
    "        for event in event_stream:\n",
    "            if \"chunk\" in event:\n",
    "                print(f\"Agent Response: {event['chunk']['bytes'].decode()}\")\n",
    "            elif \"returnControl\" in event:\n",
    "                return_control = event[\"returnControl\"]\n",
    "                logger.info(f\"Return Control Event: {json.dumps(return_control, indent=2)}\")\n",
    "\n",
    "                # Simulate follow-up handling\n",
    "                print(\"The agent returned control for action. Here are the details:\")\n",
    "                for invocation in return_control.get(\"invocationInputs\", []):\n",
    "                    action_group = invocation[\"functionInvocationInput\"][\"actionGroup\"]\n",
    "                    function = invocation[\"functionInvocationInput\"][\"function\"]\n",
    "                    parameters = invocation[\"functionInvocationInput\"][\"parameters\"]\n",
    "                    print(f\"Action Group: {action_group}, Function: {function}, Parameters: {parameters}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during agent invocation: {e}\")\n",
    "        print({\"error\": str(e)})\n",
    "\n",
    "# Prompt the agent with an unsupported request\n",
    "invoke_agent_with_roc(\"Can you book air travel for tonight?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
